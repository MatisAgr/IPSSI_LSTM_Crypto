{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ec4426",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf03a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac75ce",
   "metadata": {},
   "source": [
    "## Récupération des data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91d94e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset BTC/USD original shape: (7258717, 6)\n",
      "Colonnes: ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33662\\AppData\\Local\\Temp\\ipykernel_16652\\2214997775.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  btcusd_daily = btcusd_data['Close'].resample('H').last()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset BTC/USD réduit à 1 par heure : (120980, 2)\n",
      "\n",
      "Premières lignes:\n",
      "                 Date  Close\n",
      "0 2012-01-01 10:00:00   4.58\n",
      "1 2012-01-01 11:00:00   4.58\n",
      "2 2012-01-01 12:00:00   4.58\n",
      "3 2012-01-01 13:00:00   4.58\n",
      "4 2012-01-01 14:00:00   4.58\n",
      "\n",
      "Dernières lignes:\n",
      "                      Date     Close\n",
      "120975 2025-10-20 19:00:00  110840.0\n",
      "120976 2025-10-20 20:00:00  111133.0\n",
      "120977 2025-10-20 21:00:00  110595.0\n",
      "120978 2025-10-20 22:00:00  110860.0\n",
      "120979 2025-10-20 23:00:00  110595.0\n",
      "\n",
      "Données préparées pour le modèle: shape = (120980, 1)\n"
     ]
    }
   ],
   "source": [
    "btcusd_data = pd.read_csv('./data/btcusd_1-min_data.csv')\n",
    "\n",
    "print(f\"Dataset BTC/USD original shape: {btcusd_data.shape}\")\n",
    "print(f\"Colonnes: {btcusd_data.columns.tolist()}\")\n",
    "\n",
    "# convertir le Timestamp Unix en datetime\n",
    "btcusd_data['Timestamp'] = pd.to_datetime(btcusd_data['Timestamp'], unit='s')\n",
    "\n",
    "# trier par timestamp\n",
    "btcusd_data = btcusd_data.sort_values('Timestamp').reset_index(drop=True)\n",
    "\n",
    "# 1 donnée par heure\n",
    "btcusd_data.set_index('Timestamp', inplace=True)\n",
    "btcusd_daily = btcusd_data['Close'].resample('H').last()\n",
    "btcusd_daily = btcusd_daily.dropna().reset_index()\n",
    "btcusd_daily.columns = ['Date', 'Close']\n",
    "\n",
    "print(f\"\\nDataset BTC/USD réduit à 1 par heure : {btcusd_daily.shape}\")\n",
    "print(f\"\\nPremières lignes:\")\n",
    "print(btcusd_daily.head())\n",
    "print(f\"\\nDernières lignes:\")\n",
    "print(btcusd_daily.tail())\n",
    "\n",
    "# utiliser la colonne close\n",
    "data = btcusd_daily['Close'].values.reshape(-1, 1)\n",
    "print(f\"\\nDonnées préparées pour le modèle: shape = {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fefb68",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8dcc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# si le modèle ne s'améliore pas pendant 5 epochs, arrêter l'entraînement\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# si le modèle ne s'améliore pas pendant 3 epochs, réduire le taux d'apprentissage\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "# sauvegarder le meilleur modèle\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'models/best_bitcoin_model.h5',\n",
    "    monitor='loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [tensorboard_callback, early_stopping, reduce_lr, model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b043a1",
   "metadata": {},
   "source": [
    "## Normalisation, model, entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e9bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de séquences d'entraînement: 3779\n",
      "Look back: 60 heures\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résumé du modèle:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m66,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m30,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,757</span> (381.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,757\u001b[0m (381.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,757</span> (381.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,757\u001b[0m (381.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entraînement du modèle...\n",
      "TensorBoard logs: logs/fit/20251021-153759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0018 - mae: 0.0225\n",
      "Epoch 1: loss improved from inf to 0.00094, saving model to models/best_bitcoin_model.h5\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.00094, saving model to models/best_bitcoin_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 98ms/step - loss: 0.0018 - mae: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "Epoch 2/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 8.1419e-04 - mae: 0.0129\n",
      "Epoch 2: loss improved from 0.00094 to 0.00052, saving model to models/best_bitcoin_model.h5\n",
      "\n",
      "Epoch 2: loss improved from 0.00094 to 0.00052, saving model to models/best_bitcoin_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 93ms/step - loss: 8.1411e-04 - mae: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "Epoch 3/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 5.2733e-04 - mae: 0.0130\n",
      "Epoch 3: loss improved from 0.00052 to 0.00037, saving model to models/best_bitcoin_model.h5\n",
      "\n",
      "Epoch 3: loss improved from 0.00052 to 0.00037, saving model to models/best_bitcoin_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 95ms/step - loss: 5.2729e-04 - mae: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m   4/3779\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:42\u001b[0m 123ms/step - loss: 0.0013 - mae: 0.0214   Epoch 4/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2.4196e-04 - mae: 0.0090\n",
      "Epoch 4: loss improved from 0.00037 to 0.00025, saving model to models/best_bitcoin_model.h5\n",
      "\n",
      "Epoch 4: loss improved from 0.00037 to 0.00025, saving model to models/best_bitcoin_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 97ms/step - loss: 2.4196e-04 - mae: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m   7/3779\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:30\u001b[0m 120ms/step - loss: 1.5898e-05 - mae: 0.0031Epoch 5/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.2895e-04 - mae: 0.0069\n",
      "Epoch 5: loss improved from 0.00025 to 0.00017, saving model to models/best_bitcoin_model.h5\n",
      "\n",
      "Epoch 5: loss improved from 0.00025 to 0.00017, saving model to models/best_bitcoin_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 98ms/step - loss: 1.2896e-04 - mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m   1/3779\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:47\u001b[0m 219ms/step - loss: 9.8021e-05 - mae: 0.0093Epoch 6/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 1.5025e-04 - mae: 0.0071\n",
      "Epoch 6: loss improved from 0.00017 to 0.00015, saving model to models/best_bitcoin_model.h5\n",
      "\n",
      "Epoch 6: loss improved from 0.00017 to 0.00015, saving model to models/best_bitcoin_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 92ms/step - loss: 1.5025e-04 - mae: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m   2/3779\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:32\u001b[0m 104ms/step - loss: 1.0424e-05 - mae: 0.0027 Epoch 7/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.1406e-04 - mae: 0.0084\n",
      "Epoch 7: loss did not improve from 0.00015\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 87ms/step - loss: 2.1405e-04 - mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 7: loss did not improve from 0.00015\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 87ms/step - loss: 2.1405e-04 - mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.3656e-04 - mae: 0.0061\n",
      "Epoch 8: loss did not improve from 0.00015\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 98ms/step - loss: 1.3656e-04 - mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 8: loss did not improve from 0.00015\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 98ms/step - loss: 1.3656e-04 - mae: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 8.2532e-05 - mae: 0.0055\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 9: loss improved from 0.00015 to 0.00010, saving model to models/best_bitcoin_model.h5\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 9: loss improved from 0.00015 to 0.00010, saving model to models/best_bitcoin_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 99ms/step - loss: 8.2536e-05 - mae: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "Epoch 10/10\n",
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 3.5521e-05 - mae: 0.0037\n",
      "Epoch 10: loss improved from 0.00010 to 0.00004, saving model to models/best_bitcoin_model.h5\n",
      "\n",
      "Epoch 10: loss improved from 0.00010 to 0.00004, saving model to models/best_bitcoin_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3779/3779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 100ms/step - loss: 3.5523e-05 - mae: 0.0037 - learning_rate: 5.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "Entraînement terminé!\n",
      "Meilleur modèle sauvegardé dans: models/best_bitcoin_model.h5\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "Entraînement terminé!\n",
      "Meilleur modèle sauvegardé dans: models/best_bitcoin_model.h5\n"
     ]
    }
   ],
   "source": [
    "# normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "look_back = 60  # utiliser 60 heures pour prédire le jour suivant\n",
    "batch_size = 32\n",
    "\n",
    "# créer le générateur de séquences\n",
    "train_generator = TimeseriesGenerator(data_normalized, data_normalized,\n",
    "                                      length=look_back, batch_size=batch_size)\n",
    "\n",
    "print(f\"Nombre de séquences d'entraînement: {len(train_generator)}\")\n",
    "print(f\"Look back: {look_back} heures\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# model LSTM\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(look_back, 1)),\n",
    "    LSTM(100, return_sequences=True, input_shape=(look_back, 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "print(f\"\\nRésumé du modèle:\")\n",
    "model.summary()\n",
    "\n",
    "# training du model\n",
    "print(f\"\\nEntraînement du modèle...\")\n",
    "print(f\"TensorBoard logs: {log_dir}\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(f\"\\nEntraînement terminé!\")\n",
    "print(f\"Meilleur modèle sauvegardé dans: models/best_bitcoin_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06873c13",
   "metadata": {},
   "source": [
    "## Évaluation et visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31566b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer le générateur de test\n",
    "test_generator = TimeseriesGenerator(data_normalized, data_normalized,\n",
    "                                     length=look_back, batch_size=1)\n",
    "\n",
    "# faire les prédictions\n",
    "predictions_normalized = model.predict(test_generator, verbose=0)\n",
    "\n",
    "# inverser la normalisation\n",
    "predictions = scaler.inverse_transform(predictions_normalized)\n",
    "\n",
    "# récupérer les vraies valeurs\n",
    "real_values = data[look_back:]\n",
    "\n",
    "# créer les visualisations\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# graphique 1: Toutes les données quotidiennes\n",
    "axes[0].plot(real_values, label='Vraies Valeurs', linewidth=2, marker='o', markersize=4, alpha=0.7)\n",
    "axes[0].plot(predictions, label='Prédictions', linewidth=2, marker='s', markersize=4, alpha=0.7)\n",
    "axes[0].set_title('Prédiction du cours Bitcoin (BTC/USD) - Données quotidiennes', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Jours')\n",
    "axes[0].set_ylabel('Prix (USD)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2: Zoom sur les 60 dernières heures\n",
    "start_idx = max(0, len(real_values) - 60)\n",
    "axes[1].plot(real_values[start_idx:], label='Vraies Valeurs', linewidth=2, marker='o', markersize=6)\n",
    "axes[1].plot(predictions[start_idx:], label='Prédictions', linewidth=2, marker='s', markersize=6)\n",
    "axes[1].set_title('Zoom sur les 60 dernières heures', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Heures')\n",
    "axes[1].set_ylabel('Prix (USD)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculer les métriques d'erreur\n",
    "mse = mean_squared_error(real_values, predictions)\n",
    "mae = mean_absolute_error(real_values, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"\\nMétriques de performance:\")\n",
    "print(f\"MSE (Mean Squared Error): {mse:.4f}\")\n",
    "print(f\"MAE (Mean Absolute Error): ${mae:.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): ${rmse:.2f}\")\n",
    "print(f\"Nombre de prédictions: {len(predictions)}\")\n",
    "print(f\"\\nPrix moyen prédit: ${predictions.mean():.2f}\")\n",
    "print(f\"Prix moyen réel: ${real_values.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
