# üìä Pr√©diction de Prix BTC/USD avec Deep Learning

Ce projet impl√©mente plusieurs architectures de r√©seaux de neurones pour pr√©dire le prix du Bitcoin (BTC/USD) √† partir de donn√©es historiques minute par minute.

## üìÅ Structure du Projet

```
LSTM/
‚îú‚îÄ‚îÄ cryptoLSTM-VeryDeepLearning.ipynb  # Mod√®le LSTM principal
‚îú‚îÄ‚îÄ cryptoTFT.ipynb                     # Mod√®le Temporal Fusion Transformer
‚îú‚îÄ‚îÄ btcusd_1-min_data.csv              # Dataset (donn√©es minute)
‚îú‚îÄ‚îÄ best_lstm_model.keras              # Meilleur mod√®le LSTM sauvegard√©
‚îú‚îÄ‚îÄ best_tft_model.keras               # Mod√®le TFT sauvegard√©
‚îú‚îÄ‚îÄ best_tft_optimized.keras           # Mod√®le TFT optimis√©
‚îî‚îÄ‚îÄ logs/                              # Logs TensorBoard
```

## üìà Dataset

- **Source** : Donn√©es BTC/USD historiques
- **Fr√©quence** : 1 minute
- **Taille utilis√©e** : 20,000 derni√®res valeurs
- **S√©quence d'entr√©e** : 120 timesteps
- **Split** : 80% entra√Ænement / 20% test

## üß† Mod√®le LSTM - Architecture All√©g√©e (Recommand√©)

### Architecture

```
Input (120 timesteps, 1 feature)
    ‚Üì
Conv1D (32 filters, kernel=3) + BatchNorm + ReLU + Dropout(0.2)
    ‚Üì
LSTM (64 units, return_sequences=True) + Dropout(0.3)
    ‚Üì
LSTM (32 units, return_sequences=False) + Dropout(0.3)
    ‚Üì
Dense (16 units, ReLU) + Dropout(0.2)
    ‚Üì
Dense (1 unit) ‚Üí Prix pr√©dit
```

### Caract√©ristiques Techniques

- **Param√®tres totaux** : 38,049
- **Optimiseur** : Adam
- **Loss** : Mean Squared Error (MSE)
- **Callbacks** :
  - ReduceLROnPlateau (patience=5, factor=0.5)
  - EarlyStopping (patience=10)
  - ModelCheckpoint (sauvegarde du meilleur mod√®le)
  - TensorBoard (visualisation)

### R√©sultats

| M√©trique | Valeur |
|----------|--------|
| **R¬≤ Score** | **0.92** ‚úÖ |
| **MAE** | $434.38 |
| **RMSE** | $486.32 |
| **Temps d'entra√Ænement** | ~4.5 minutes |

#### Pr√©dictions LSTM

![R√©sultats complets LSTM](graphs/bloc2-all.png)
*Comparaison des pr√©dictions LSTM vs prix r√©els sur l'ensemble du dataset de test*

![Zoom 100 premi√®res pr√©dictions](graphs/bloc2-100-firsts.png)
*D√©tail des 100 premi√®res pr√©dictions - excellente pr√©cision*

![Zoom 100 derni√®res pr√©dictions](graphs/bloc2-100-lasts.png)
*D√©tail des 100 derni√®res pr√©dictions*

#### √âvolution de l'entra√Ænement

![Loss et MAE pendant l'entra√Ænement](graphs/bloc2-loss-mae.png)
*√âvolution de la perte (MSE) et du MAE pendant l'entra√Ænement et validation*

### Points Forts

- ‚úÖ **Excellent compromis** vitesse/performance
- ‚úÖ **Architecture simple** et efficace
- ‚úÖ **Conv1D** pour extraction de features temporelles
- ‚úÖ **LSTM en cascade** pour capturer les d√©pendances longues
- ‚úÖ **Dropout strat√©gique** pour √©viter l'overfitting
- ‚úÖ **BatchNormalization** pour stabiliser l'entra√Ænement

## üìä Comparaison des Architectures LSTM Test√©es

| Architecture | Param√®tres | R¬≤ Score | MAE | RMSE | Temps | Observations |
|--------------|-----------|----------|-----|------|-------|--------------|
| **LSTM Initial** | 31,901 | 0.79 | $89.95 | $115.85 | ~2 min | Simple, rapide |
| **LSTM Am√©lior√©** | 136,911 | **0.97** | $137.86 | $177.86 | ~5 min | ‚úÖ Meilleur R¬≤ |
| **Very Deep Learning** | 250,511 | 0.29 | $813.42 | $873.58 | ~8 min | ‚ö†Ô∏è Overfitting |
| **LSTM All√©g√©** | 38,049 | **0.92** | $434.38 | $486.32 | ~4.5 min | ‚ö° **Optimal** |

### üí° Enseignements

- Le **mod√®le all√©g√©** offre le meilleur compromis :
  - 85% moins de param√®tres que Very Deep Learning
  - 40% plus rapide
  - Score de pr√©diction excellent (R¬≤ = 0.92)
  
- Le **mod√®le am√©lior√©** (R¬≤ = 0.97) reste le plus performant mais n√©cessite plus de ressources

- Le **Very Deep Learning** montre qu'une architecture trop complexe peut mener √† l'overfitting pour ce probl√®me

## üöÄ Bonus : Temporal Fusion Transformer (TFT)

### Architecture TFT

Le **Temporal Fusion Transformer** est une architecture avanc√©e utilisant l'attention multi-t√™tes pour les s√©ries temporelles.

```
Input (120 timesteps)
    ‚Üì
Dense Projection (1 ‚Üí 64 dimensions)
    ‚Üì
+ Positional Encoding
    ‚Üì
3x Transformer Encoder Layers:
    - Multi-Head Attention (4 t√™tes)
    - Layer Normalization
    - Feed-Forward Network (256 unit√©s)
    - Residual Connections
    - Dropout (0.1)
    ‚Üì
Derni√®re sortie temporelle
    ‚Üì
Dense(128, ReLU) ‚Üí Dense(64, ReLU) ‚Üí Dense(1)
    ‚Üì
Prix pr√©dit
```

### Composants Cl√©s

1. **Multi-Head Attention** : Capture diff√©rentes relations temporelles simultan√©ment
2. **Positional Encoding** : Encode la position temporelle dans la s√©quence
3. **Layer Normalization** : Stabilise l'entra√Ænement
4. **Residual Connections** : Facilite le gradient flow
5. **Feed-Forward Networks** : Capture les relations non-lin√©aires

### R√©sultats TFT

| Mod√®le | Param√®tres | R¬≤ Score | MAE | RMSE | Temps |
|--------|-----------|----------|-----|------|-------|
| **TFT Original** | ~150,000 | 0.77 | $725.08 | $806.45 | ~13 min |
| **TFT Optimis√©** | ~400,000 | Vari√© | Variable | Variable | ~15-20 min |

#### Pr√©dictions TFT

![R√©sultats TFT](graphs/tft-results.png)
*Comparaison des pr√©dictions TFT vs prix r√©els*

![Zoom 100 premi√®res pr√©dictions TFT](graphs/tft-100-first.png)
*D√©tail des 100 premi√®res pr√©dictions TFT*

#### √âvolution de l'entra√Ænement TFT

![Loss et MAE TFT](graphs/tft-loss-mae.png)
*√âvolution de la perte (MSE) et du MAE pendant l'entra√Ænement du TFT*

### TFT vs LSTM : Analyse Comparative

| Caract√©ristique | LSTM | TFT |
|-----------------|------|-----|
| **D√©pendances longues** | ‚ö†Ô∏è Limit√©es | ‚úÖ Excellentes |
| **Parall√©lisation** | ‚ùå S√©quentiel | ‚úÖ Parall√®le |
| **Interpr√©tabilit√©** | ‚ùå Faible | ‚úÖ Attention weights |
| **Complexit√©** | Simple | Plus complexe |
| **Performance ici** | **‚úÖ R¬≤ = 0.92-0.97** | ‚ö†Ô∏è R¬≤ = 0.77 |

### üîç Pourquoi le TFT est moins performant ?

1. **Taille du dataset** : 20,000 valeurs insuffisantes pour un transformer
2. **Probl√®me univari√©** : TFT con√ßu pour probl√®mes multi-vari√©s complexes
3. **Hyperparam√®tres** : Besoin de fine-tuning approfondi
4. **Nature du probl√®me** : LSTM excellent pour s√©ries temporelles univari√©es simples

### üí° Le TFT serait plus performant avec :

- ‚úÖ Plus de donn√©es (>100,000 points)
- ‚úÖ Features multiples (volume, bid/ask, indicateurs techniques)
- ‚úÖ Fine-tuning des hyperparam√®tres
- ‚úÖ Plus d'epochs d'entra√Ænement
- ‚úÖ Probl√®mes multi-horizons (pr√©dire plusieurs timesteps)

## üõ†Ô∏è Installation et Utilisation

### Pr√©requis

```bash
pip install pandas numpy matplotlib tensorflow scikit-learn
```

### Ex√©cution

1. **Mod√®le LSTM** :
   ```bash
   # Ouvrir cryptoLSTM-VeryDeepLearning.ipynb dans Jupyter/VSCode
   # Ex√©cuter toutes les cellules
   ```

2. **Mod√®le TFT** :
   ```bash
   # Ouvrir cryptoTFT.ipynb
   # Ex√©cuter toutes les cellules
   ```

3. **Visualisation TensorBoard** :
   ```bash
   tensorboard --logdir=logs/fit
   ```

## üìä Visualisations Disponibles

Toutes les visualisations sont disponibles dans le dossier `graphs/` :

### LSTM
- `bloc2-all.png` : Pr√©dictions compl√®tes sur le dataset de test
- `bloc2-100-firsts.png` : Zoom sur les 100 premi√®res pr√©dictions
- `bloc2-100-lasts.png` : Zoom sur les 100 derni√®res pr√©dictions
- `bloc2-loss-mae.png` : √âvolution de la loss et du MAE

### TFT
- `tft-results.png` : Pr√©dictions compl√®tes TFT
- `tft-100-first.png` : Zoom sur les 100 premi√®res pr√©dictions TFT
- `tft-loss-mae.png` : √âvolution de la loss et du MAE pour TFT

### Exemple de visualisation

![Comparaison LSTM](graphs/bloc2-all.png)

- **Prix r√©el vs pr√©dit** : Comparaison sur tout le dataset de test
- **Zoom 100 premi√®res pr√©dictions** : Analyse d√©taill√©e du d√©but
- **Zoom 100 derni√®res pr√©dictions** : Analyse de la fin
- **√âvolution de la loss** : Training vs Validation
- **√âvolution du MAE** : Suivi de l'erreur absolue moyenne
- **TensorBoard** : M√©triques en temps r√©el pendant l'entra√Ænement

## üéØ Conclusions

### Pour ce projet de pr√©diction BTC/USD :

1. **Gagnant** : **LSTM All√©g√©** (R¬≤ = 0.92)
   - Meilleur compromis vitesse/performance
   - Architecture simple et efficace
   - Id√©al pour un environnement d'apprentissage

2. **Plus performant** : **LSTM Am√©lior√©** (R¬≤ = 0.97)
   - Meilleure pr√©cision absolue
   - N√©cessite plus de ressources

3. **Exploratoire** : **TFT** (R¬≤ = 0.77)
   - Architecture moderne et int√©ressante
   - Inadapt√©e pour ce probl√®me sp√©cifique
   - Potentiel sur des datasets plus complexes

### üîë Recommandation

Pour la **pr√©diction de prix crypto univari√©**, privil√©gier :
- **LSTM All√©g√©** pour rapidit√© et efficacit√©
- **LSTM Am√©lior√©** pour pr√©cision maximale
- √âviter les architectures trop complexes (overfitting)

### üìö Pour aller plus loin

- Ajouter des features suppl√©mentaires (volume, RSI, MACD, etc.)
- Tester sur d'autres cryptomonnaies
- Impl√©menter un syst√®me de trading automatis√©
- Essayer des fen√™tres temporelles variables
- Comparer avec d'autres architectures (GRU, Bidirectional LSTM, etc.)

---

**Auteur** : Julie  
**Date** : Octobre 2025  
**Framework** : TensorFlow/Keras  
**Dataset** : BTC/USD 1-minute data
